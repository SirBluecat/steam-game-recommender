{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c4d2d3a-4206-4283-884c-1c32a734b8eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtempfile\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f169f6c-520a-4d2e-8a58-f96a4a29d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73fc1e1d-3e20-487b-a8c3-f163bae5bff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\Bluecat\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...:   0%|                                                                              | 0/4 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                                                         | 0/1 [00:00<?, ? url/s]\u001b[A\n",
      "Dl Size...:  25%|█████████████████▌                                                    | 1/4 [00:00<00:01,  2.14 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...:  50%|███████████████████████████████████                                   | 2/4 [00:00<00:00,  2.14 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                                                         | 0/1 [00:00<?, ? url/s]\u001b[A\n",
      "Dl Size...:  75%|████████████████████████████████████████████████████▌                 | 3/4 [00:00<00:00,  5.55 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...: 100%|██████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  5.55 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.29 url/s]\n",
      "Dl Size...: 100%|██████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  5.55 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.29 url/s]\n",
      "Dl Size...: 100%|██████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  5.55 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:   0%|                                                                | 0/1 [00:00<?, ? file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.29 url/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  5.55 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.07 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  4.26 MiB/s]\n",
      "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.06 url/s]\n",
      "Generating splits...:   0%|                                                                 | 0/1 [00:00<?, ? splits/s]\n",
      "Generating train examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating train examples...: 481 examples [00:00, 4809.98 examples/s]\u001b[A\n",
      "Generating train examples...: 1106 examples [00:00, 5624.00 examples/s]\u001b[A\n",
      "Generating train examples...: 1702 examples [00:00, 5776.94 examples/s]\u001b[A\n",
      "Generating train examples...: 2321 examples [00:00, 5939.16 examples/s]\u001b[A\n",
      "Generating train examples...: 2940 examples [00:00, 6014.28 examples/s]\u001b[A\n",
      "Generating train examples...: 3571 examples [00:00, 6114.56 examples/s]\u001b[A\n",
      "Generating train examples...: 4199 examples [00:00, 6148.43 examples/s]\u001b[A\n",
      "Generating train examples...: 4814 examples [00:00, 6029.45 examples/s]\u001b[A\n",
      "Generating train examples...: 5422 examples [00:00, 6044.99 examples/s]\u001b[A\n",
      "Generating train examples...: 6041 examples [00:01, 6070.75 examples/s]\u001b[A\n",
      "Generating train examples...: 6655 examples [00:01, 6091.74 examples/s]\u001b[A\n",
      "Generating train examples...: 7265 examples [00:01, 6058.83 examples/s]\u001b[A\n",
      "Generating train examples...: 7884 examples [00:01, 6079.96 examples/s]\u001b[A\n",
      "Generating train examples...: 8518 examples [00:01, 6139.48 examples/s]\u001b[A\n",
      "Generating train examples...: 9133 examples [00:01, 6127.21 examples/s]\u001b[A\n",
      "Generating train examples...: 9752 examples [00:01, 6145.97 examples/s]\u001b[A\n",
      "Generating train examples...: 10367 examples [00:01, 6100.80 examples/s]\u001b[A\n",
      "Generating train examples...: 10978 examples [00:01, 6067.41 examples/s]\u001b[A\n",
      "Generating train examples...: 11604 examples [00:01, 6124.65 examples/s]\u001b[A\n",
      "Generating train examples...: 12218 examples [00:02, 6115.22 examples/s]\u001b[A\n",
      "Generating train examples...: 12830 examples [00:02, 6044.52 examples/s]\u001b[A\n",
      "Generating train examples...: 13435 examples [00:02, 5923.34 examples/s]\u001b[A\n",
      "Generating train examples...: 14028 examples [00:02, 5856.65 examples/s]\u001b[A\n",
      "Generating train examples...: 14642 examples [00:02, 5930.80 examples/s]\u001b[A\n",
      "Generating train examples...: 15236 examples [00:02, 5907.25 examples/s]\u001b[A\n",
      "Generating train examples...: 15876 examples [00:02, 6034.91 examples/s]\u001b[A\n",
      "Generating train examples...: 16502 examples [00:02, 6083.54 examples/s]\u001b[A\n",
      "Generating train examples...: 17111 examples [00:02, 6070.49 examples/s]\u001b[A\n",
      "Generating train examples...: 17719 examples [00:02, 6055.32 examples/s]\u001b[A\n",
      "Generating train examples...: 18342 examples [00:03, 6089.16 examples/s]\u001b[A\n",
      "Generating train examples...: 18952 examples [00:03, 6038.49 examples/s]\u001b[A\n",
      "Generating train examples...: 19569 examples [00:03, 6059.51 examples/s]\u001b[A\n",
      "Generating train examples...: 20205 examples [00:03, 6130.51 examples/s]\u001b[A\n",
      "Generating train examples...: 20819 examples [00:03, 6104.41 examples/s]\u001b[A\n",
      "Generating train examples...: 21435 examples [00:03, 6102.82 examples/s]\u001b[A\n",
      "Generating train examples...: 22046 examples [00:03, 6050.99 examples/s]\u001b[A\n",
      "Generating train examples...: 22652 examples [00:03, 6000.33 examples/s]\u001b[A\n",
      "Generating train examples...: 23275 examples [00:03, 6068.18 examples/s]\u001b[A\n",
      "Generating train examples...: 23882 examples [00:03, 6014.66 examples/s]\u001b[A\n",
      "Generating train examples...: 24502 examples [00:04, 6058.89 examples/s]\u001b[A\n",
      "Generating train examples...: 25109 examples [00:04, 5956.15 examples/s]\u001b[A\n",
      "Generating train examples...: 25726 examples [00:04, 6019.03 examples/s]\u001b[A\n",
      "Generating train examples...: 26340 examples [00:04, 6036.97 examples/s]\u001b[A\n",
      "Generating train examples...: 26952 examples [00:04, 6049.87 examples/s]\u001b[A\n",
      "Generating train examples...: 27558 examples [00:04, 6034.95 examples/s]\u001b[A\n",
      "Generating train examples...: 28189 examples [00:04, 6116.70 examples/s]\u001b[A\n",
      "Generating train examples...: 28819 examples [00:04, 6157.11 examples/s]\u001b[A\n",
      "Generating train examples...: 29457 examples [00:04, 6205.04 examples/s]\u001b[A\n",
      "Generating train examples...: 30089 examples [00:04, 6220.80 examples/s]\u001b[A\n",
      "Generating train examples...: 30712 examples [00:05, 6132.13 examples/s]\u001b[A\n",
      "Generating train examples...: 31326 examples [00:05, 6074.17 examples/s]\u001b[A\n",
      "Generating train examples...: 31934 examples [00:05, 6040.27 examples/s]\u001b[A\n",
      "Generating train examples...: 32539 examples [00:05, 5937.99 examples/s]\u001b[A\n",
      "Generating train examples...: 33143 examples [00:05, 5959.04 examples/s]\u001b[A\n",
      "Generating train examples...: 33784 examples [00:05, 6076.94 examples/s]\u001b[A\n",
      "Generating train examples...: 34419 examples [00:05, 6139.56 examples/s]\u001b[A\n",
      "Generating train examples...: 35036 examples [00:05, 6130.42 examples/s]\u001b[A\n",
      "Generating train examples...: 35670 examples [00:05, 6192.61 examples/s]\u001b[A\n",
      "Generating train examples...: 36290 examples [00:05, 6163.44 examples/s]\u001b[A\n",
      "Generating train examples...: 36907 examples [00:06, 6075.04 examples/s]\u001b[A\n",
      "Generating train examples...: 37534 examples [00:06, 6114.55 examples/s]\u001b[A\n",
      "Generating train examples...: 38146 examples [00:06, 6098.11 examples/s]\u001b[A\n",
      "Generating train examples...: 38756 examples [00:06, 6032.22 examples/s]\u001b[A\n",
      "Generating train examples...: 39360 examples [00:06, 5944.33 examples/s]\u001b[A\n",
      "Generating train examples...: 39955 examples [00:06, 5930.94 examples/s]\u001b[A\n",
      "Generating train examples...: 40549 examples [00:06, 5898.80 examples/s]\u001b[A\n",
      "Generating train examples...: 41145 examples [00:06, 5899.48 examples/s]\u001b[A\n",
      "Generating train examples...: 41774 examples [00:06, 5997.34 examples/s]\u001b[A\n",
      "Generating train examples...: 42402 examples [00:07, 6063.19 examples/s]\u001b[A\n",
      "Generating train examples...: 43009 examples [00:07, 6047.24 examples/s]\u001b[A\n",
      "Generating train examples...: 43621 examples [00:07, 6053.58 examples/s]\u001b[A\n",
      "Generating train examples...: 44228 examples [00:07, 6058.46 examples/s]\u001b[A\n",
      "Generating train examples...: 44848 examples [00:07, 6082.54 examples/s]\u001b[A\n",
      "Generating train examples...: 45458 examples [00:07, 6078.51 examples/s]\u001b[A\n",
      "Generating train examples...: 46066 examples [00:07, 6025.02 examples/s]\u001b[A\n",
      "Generating train examples...: 46671 examples [00:07, 6015.72 examples/s]\u001b[A\n",
      "Generating train examples...: 47273 examples [00:07, 5981.43 examples/s]\u001b[A\n",
      "Generating train examples...: 47908 examples [00:07, 6090.84 examples/s]\u001b[A\n",
      "Generating train examples...: 48518 examples [00:08, 6025.25 examples/s]\u001b[A\n",
      "Generating train examples...: 49121 examples [00:08, 5921.46 examples/s]\u001b[A\n",
      "Generating train examples...: 49714 examples [00:08, 5855.20 examples/s]\u001b[A\n",
      "Generating train examples...: 50319 examples [00:08, 5912.29 examples/s]\u001b[A\n",
      "Generating train examples...: 50955 examples [00:08, 6044.41 examples/s]\u001b[A\n",
      "Generating train examples...: 51578 examples [00:08, 6082.62 examples/s]\u001b[A\n",
      "Generating train examples...: 52200 examples [00:08, 6123.41 examples/s]\u001b[A\n",
      "Generating train examples...: 52820 examples [00:08, 6127.97 examples/s]\u001b[A\n",
      "Generating train examples...: 53452 examples [00:08, 6170.76 examples/s]\u001b[A\n",
      "Generating train examples...: 54073 examples [00:08, 6182.45 examples/s]\u001b[A\n",
      "Generating train examples...: 54692 examples [00:09, 6093.70 examples/s]\u001b[A\n",
      "Generating train examples...: 55302 examples [00:09, 6075.34 examples/s]\u001b[A\n",
      "Generating train examples...: 55910 examples [00:09, 6073.39 examples/s]\u001b[A\n",
      "Generating train examples...: 56518 examples [00:09, 6021.64 examples/s]\u001b[A\n",
      "Generating train examples...: 57132 examples [00:09, 6056.71 examples/s]\u001b[A\n",
      "Generating train examples...: 57738 examples [00:09, 5984.40 examples/s]\u001b[A\n",
      "Generating train examples...: 58345 examples [00:09, 5992.00 examples/s]\u001b[A\n",
      "Generating train examples...: 58973 examples [00:09, 6059.38 examples/s]\u001b[A\n",
      "Generating train examples...: 59580 examples [00:09, 6035.53 examples/s]\u001b[A\n",
      "Generating train examples...: 60184 examples [00:09, 5964.57 examples/s]\u001b[A\n",
      "Generating train examples...: 60781 examples [00:10, 5930.03 examples/s]\u001b[A\n",
      "Generating train examples...: 61409 examples [00:10, 6015.62 examples/s]\u001b[A\n",
      "Generating train examples...: 62046 examples [00:10, 6102.52 examples/s]\u001b[A\n",
      "Generating train examples...: 62660 examples [00:10, 6113.64 examples/s]\u001b[A\n",
      "Generating train examples...: 63281 examples [00:10, 6138.61 examples/s]\u001b[A\n",
      "Generating train examples...: 63900 examples [00:10, 6151.39 examples/s]\u001b[A\n",
      "Generating train examples...: 64527 examples [00:10, 6186.81 examples/s]\u001b[A\n",
      "Generating train examples...: 65162 examples [00:10, 6217.03 examples/s]\u001b[A\n",
      "Generating train examples...: 65784 examples [00:10, 6217.88 examples/s]\u001b[A\n",
      "Generating train examples...: 66425 examples [00:10, 6256.66 examples/s]\u001b[A\n",
      "Generating train examples...: 67051 examples [00:11, 6183.77 examples/s]\u001b[A\n",
      "Generating train examples...: 67672 examples [00:11, 6191.54 examples/s]\u001b[A\n",
      "Generating train examples...: 68293 examples [00:11, 6196.11 examples/s]\u001b[A\n",
      "Generating train examples...: 68913 examples [00:11, 6160.52 examples/s]\u001b[A\n",
      "Generating train examples...: 69530 examples [00:11, 6145.03 examples/s]\u001b[A\n",
      "Generating train examples...: 70145 examples [00:11, 6047.43 examples/s]\u001b[A\n",
      "Generating train examples...: 70751 examples [00:11, 5980.57 examples/s]\u001b[A\n",
      "Generating train examples...: 71355 examples [00:11, 5980.46 examples/s]\u001b[A\n",
      "Generating train examples...: 71954 examples [00:11, 5948.16 examples/s]\u001b[A\n",
      "Generating train examples...: 72587 examples [00:11, 6043.10 examples/s]\u001b[A\n",
      "Generating train examples...: 73192 examples [00:12, 6023.16 examples/s]\u001b[A\n",
      "Generating train examples...: 73814 examples [00:12, 6081.52 examples/s]\u001b[A\n",
      "Generating train examples...: 74456 examples [00:12, 6163.90 examples/s]\u001b[A\n",
      "Generating train examples...: 75073 examples [00:12, 6147.41 examples/s]\u001b[A\n",
      "Generating train examples...: 75688 examples [00:12, 6135.82 examples/s]\u001b[A\n",
      "Generating train examples...: 76302 examples [00:12, 6085.01 examples/s]\u001b[A\n",
      "Generating train examples...: 76911 examples [00:12, 6023.76 examples/s]\u001b[A\n",
      "Generating train examples...: 77514 examples [00:12, 6007.85 examples/s]\u001b[A\n",
      "Generating train examples...: 78115 examples [00:12, 5818.83 examples/s]\u001b[A\n",
      "Generating train examples...: 78734 examples [00:13, 5909.57 examples/s]\u001b[A\n",
      "Generating train examples...: 79367 examples [00:13, 6015.08 examples/s]\u001b[A\n",
      "Generating train examples...: 79970 examples [00:13, 6009.46 examples/s]\u001b[A\n",
      "Generating train examples...: 80572 examples [00:13, 5959.73 examples/s]\u001b[A\n",
      "Generating train examples...: 81169 examples [00:13, 5962.74 examples/s]\u001b[A\n",
      "Generating train examples...: 81801 examples [00:13, 6050.77 examples/s]\u001b[A\n",
      "Generating train examples...: 82407 examples [00:13, 5853.50 examples/s]\u001b[A\n",
      "Generating train examples...: 83014 examples [00:13, 5899.32 examples/s]\u001b[A\n",
      "Generating train examples...: 83608 examples [00:13, 5893.98 examples/s]\u001b[A\n",
      "Generating train examples...: 84233 examples [00:13, 5981.19 examples/s]\u001b[A\n",
      "Generating train examples...: 84873 examples [00:14, 6090.63 examples/s]\u001b[A\n",
      "Generating train examples...: 85483 examples [00:14, 6053.57 examples/s]\u001b[A\n",
      "Generating train examples...: 86100 examples [00:14, 6088.02 examples/s]\u001b[A\n",
      "Generating train examples...: 86710 examples [00:14, 6037.76 examples/s]\u001b[A\n",
      "Generating train examples...: 87342 examples [00:14, 6103.27 examples/s]\u001b[A\n",
      "Generating train examples...: 87954 examples [00:14, 6105.93 examples/s]\u001b[A\n",
      "Generating train examples...: 88565 examples [00:14, 6044.06 examples/s]\u001b[A\n",
      "Generating train examples...: 89172 examples [00:14, 6033.88 examples/s]\u001b[A\n",
      "Generating train examples...: 89808 examples [00:14, 6112.49 examples/s]\u001b[A\n",
      "Generating train examples...: 90420 examples [00:14, 6112.73 examples/s]\u001b[A\n",
      "Generating train examples...: 91048 examples [00:15, 6144.26 examples/s]\u001b[A\n",
      "Generating train examples...: 91688 examples [00:15, 6201.96 examples/s]\u001b[A\n",
      "Generating train examples...: 92334 examples [00:15, 6260.18 examples/s]\u001b[A\n",
      "Generating train examples...: 92961 examples [00:15, 6162.71 examples/s]\u001b[A\n",
      "Generating train examples...: 93589 examples [00:15, 6197.15 examples/s]\u001b[A\n",
      "Generating train examples...: 94211 examples [00:15, 6197.75 examples/s]\u001b[A\n",
      "Generating train examples...: 94831 examples [00:15, 6127.74 examples/s]\u001b[A\n",
      "Generating train examples...: 95445 examples [00:15, 6059.68 examples/s]\u001b[A\n",
      "Generating train examples...: 96052 examples [00:15, 6062.72 examples/s]\u001b[A\n",
      "Generating train examples...: 96659 examples [00:15, 5958.48 examples/s]\u001b[A\n",
      "Generating train examples...: 97260 examples [00:16, 5972.29 examples/s]\u001b[A\n",
      "Generating train examples...: 97858 examples [00:16, 5939.47 examples/s]\u001b[A\n",
      "Generating train examples...: 98473 examples [00:16, 5984.01 examples/s]\u001b[A\n",
      "Generating train examples...: 99101 examples [00:16, 6060.68 examples/s]\u001b[A\n",
      "Generating train examples...: 99736 examples [00:16, 6146.60 examples/s]\u001b[A\n",
      "                                                                        \u001b[A\n",
      "Shuffling C:\\Users\\Bluecat\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1.incomplete7M9KCW\\movielens-train.tfrecord*.\u001b[A\n",
      "Shuffling C:\\Users\\Bluecat\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1.incomplete7M9KCW\\movielens-train.tfrecord*.\u001b[A\n",
      "Shuffling C:\\Users\\Bluecat\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1.incomplete7M9KCW\\movielens-train.tfrecord*.\u001b[A\n",
      "Shuffling C:\\Users\\Bluecat\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1.incomplete7M9KCW\\movielens-train.tfrecord*.\u001b[A\n",
      "Shuffling C:\\Users\\Bluecat\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1.incomplete7M9KCW\\movielens-train.tfrecord*.\u001b[A\n",
      "Shuffling C:\\Users\\Bluecat\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1.incomplete7M9KCW\\movielens-train.tfrecord*.\u001b[A\n",
      "Shuffling C:\\Users\\Bluecat\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1.incomplete7M9KCW\\movielens-train.tfrecord*.\u001b[A\n",
      "                                                                                                                       \u001b[A\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset movielens downloaded and prepared to C:\\Users\\Bluecat\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a89e2089-000c-48a0-8c75-06b7c2b109ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "503cabf5-2d6b-4a0e-8188-9af611f1d1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_title': <tf.Tensor: shape=(), dtype=string, numpy=b\"One Flew Over the Cuckoo's Nest (1975)\">, 'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'138'>}\n"
     ]
    }
   ],
   "source": [
    "for element in ratings: \n",
    "    print(element)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5909b5b7-18c8-4245-83c7-63e95c88edc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.MapDataset"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b865143-b584-4470-97d2-4521b5a5fee5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'\nFailed importing pandas. This likely means that the dataset requires additional dependencies that have to be manually installed (usually with `pip install pandas`). See setup.py extras_require.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_conda\\lib\\site-packages\\tensorflow_datasets\\core\\lazy_imports_lib.py:30\u001b[0m, in \u001b[0;36m_try_import\u001b[1;34m(module_name)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m   mod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m mod\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_conda\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_conda\\lib\\site-packages\\tensorflow_datasets\\core\\as_dataframe.py:208\u001b[0m, in \u001b[0;36mas_dataframe\u001b[1;34m(ds, ds_info)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert the dataset into a pandas dataframe.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mWarning: The dataframe will be loaded entirely in memory, you may\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m  dataframe: The `pandas.DataFrame` object\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# Raise a clean error message if panda isn't installed.\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m \u001b[43mlazy_imports_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_imports\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpandas\u001b[49m  \u001b[38;5;66;03m# pylint: disable=pointless-statement\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# Pack `as_supervised=True` datasets\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ds_info:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_conda\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py:153\u001b[0m, in \u001b[0;36mclassproperty.__get__\u001b[1;34m(self, obj, objtype)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj, objtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_conda\\lib\\site-packages\\tensorflow_datasets\\core\\lazy_imports_lib.py:137\u001b[0m, in \u001b[0;36mLazyImporter.pandas\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;129m@utils\u001b[39m\u001b[38;5;241m.\u001b[39mclassproperty\n\u001b[0;32m    135\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpandas\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[1;32m--> 137\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_try_import\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpandas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_conda\\lib\\site-packages\\tensorflow_datasets\\core\\lazy_imports_lib.py:37\u001b[0m, in \u001b[0;36m_try_import\u001b[1;34m(module_name)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     33\u001b[0m   err_msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed importing \u001b[39m\u001b[38;5;132;01m{name}\u001b[39;00m\u001b[38;5;124m. This likely means that the dataset \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires additional dependencies that have to be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanually installed (usually with `pip install \u001b[39m\u001b[38;5;132;01m{name}\u001b[39;00m\u001b[38;5;124m`). See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     36\u001b[0m              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetup.py extras_require.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mmodule_name)\n\u001b[1;32m---> 37\u001b[0m   \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr_msg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_conda\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py:381\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(e, prefix, suffix)\u001b[0m\n\u001b[0;32m    379\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    380\u001b[0m     exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 381\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m exception \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# Otherwise, modify the exception in-place\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(e\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'\nFailed importing pandas. This likely means that the dataset requires additional dependencies that have to be manually installed (usually with `pip install pandas`). See setup.py extras_require."
     ]
    }
   ],
   "source": [
    "df = tfds.as_dataframe(ratings.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030edfd5-a139-4ce4-b652-a2a61aa40d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
