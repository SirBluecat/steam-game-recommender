{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c118c95-9a03-493f-91d2-df9d34265df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fa37bc2e-16d8-4007-aa5b-fdc1027502ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4440f67d-6ba6-46e7-9e31-7a115799a166",
   "metadata": {},
   "source": [
    "# Import user reviews and game data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "417b23dd-7f91-4eab-814a-4724c31a29f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/pruned_user_data.json', \"r\") as infile:\n",
    "    user_data = json.load(infile)\n",
    "    \n",
    "with open('data/final_app_data.json', \"r\") as infile:\n",
    "    game_data = json.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6a6779-0a11-4b18-bd3e-4b2a6e550c30",
   "metadata": {},
   "source": [
    "## In version 1 of the retrieval model, we create a \"user_upvoted\" tf dataset where each entry is a movie and a user who positively reviewed it. We make dict tensor slices to support more features in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "160db26f-9bae-41a1-9793-2b0c1ba76c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_upvoted_df = pandas.DataFrame(columns=['user_id', 'game_id'])\n",
    "for user in user_data:\n",
    "    for game in user_data[user]:\n",
    "        if user_data[user][game]['voted_up?'] == True:\n",
    "            user_upvoted_df.loc[len(user_upvoted_df.index)] = [user, game]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20cee68a-3115-4902-aeff-c8f2090fcf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_upvoted_df.to_csv('data/user_upvoted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2414aa-1112-4e06-94e2-31e93bbcbbbe",
   "metadata": {},
   "source": [
    "### Change id types to ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8bf63c42-a20e-429e-a162-133225bdff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_upvoted_df[[\"user_id\", \"game_id\"]] = user_upvoted_df[[\"user_id\", \"game_id\"]].apply(pandas.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1120d8d-a68f-428d-b186-e239dd84e755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id    int64\n",
       "game_id    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_upvoted_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "22b7a86e-b0d1-4b06-8066-5c343f112809",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_upvoted_ds = tf.data.Dataset.from_tensor_slices(dict(user_upvoted_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e3ba02-5fc4-46e9-94c2-7e4917a04037",
   "metadata": {},
   "source": [
    "### Check data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e44fec66-6d32-4a8a-9810-29d27d576198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': <tf.Tensor: shape=(), dtype=string, numpy=b'76561198318922553'>, 'game_id': <tf.Tensor: shape=(), dtype=string, numpy=b'394360'>}\n"
     ]
    }
   ],
   "source": [
    "for element in user_upvoted_ds: \n",
    "    print(element)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cf83409-3da8-465d-bb47-6ee93fd7d908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(user_upvoted_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63b04c-f02e-44df-b78d-5e8e884771b2",
   "metadata": {},
   "source": [
    "## Now get the list of game_ids and create the game dataset, game_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35637468-41c2-45b2-9c4f-0b88cc713505",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_game_ids = [int(x) for x in game_data]\n",
    "game_ds = tf.data.experimental.from_list(unique_game_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38b5e8f6-d1a5-44a1-b894-ece9fed5a0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(730, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for element in game_ds: \n",
    "    print(element)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "948dd4e3-6156-4b3f-b596-66f9c1fb2d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_user_ids = [int(x) for x in user_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d938bf81-0c06-4231-9c25-c039bab9dc59",
   "metadata": {},
   "source": [
    "### Create train and test data from user_upvoted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67b85be6-5eac-434b-ba63-a1c869890066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146852"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.experimental.cardinality(user_upvoted_ds).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "927e0459-7561-40b8-a55d-9692c729faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1989)\n",
    "shuffled = user_upvoted_ds.shuffle(146_852, seed=1989, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(100_000)\n",
    "test = shuffled.skip(100_000).take(25_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628eee91-fa7e-44f0-a3e6-70a850e96cfb",
   "metadata": {},
   "source": [
    "# User and Game embedding models\n",
    "\n",
    "For both we map the unique game and user ids to a continuous range using their ids as a vocabulary, then convert to an embedding using the Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44f424e3-10c3-420b-acf2-846a48854635",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 32\n",
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.IntegerLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "    # We add an additional embedding to account for unknown tokens\n",
    "    tf.keras.layers.Embedding(len(unique_user_ids)+1, embedding_dim)\n",
    "])\n",
    "\n",
    "game_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.IntegerLookup(\n",
    "        vocabulary=unique_game_ids, mask_token=None),\n",
    "    # We add an additional embedding to account for unknown tokens\n",
    "    tf.keras.layers.Embedding(len(unique_game_ids)+1, embedding_dim)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e071bb-879b-4783-be09-b53f1ba30ea6",
   "metadata": {},
   "source": [
    "# Metric\n",
    "We use Factorized Top K metric, since it takes as its only input the candidates from the retrieval model. We need to compare the affinity score that the model calculates for this pair to the scores of all the other possible candidates\n",
    "\n",
    "Then combine this with built-in loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79b6563f-9819-40a6-b0fb-b031cd00a6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(candidates=game_ds.batch(128).map(game_model))\n",
    "task = tfrs.tasks.Retrieval(\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e7921d-18cf-410d-b57b-10cad7286a70",
   "metadata": {},
   "source": [
    "# Retrieval Model\n",
    "Defining the final model, defining training and test steps with loss functions\n",
    "\n",
    "If training_metrics is set False, we skip calculating metrics in training as well as evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e2b18d33-4a01-462a-ab7a-a6ddac1364dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (417085925.py, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[81], line 33\u001b[1;36m\u001b[0m\n\u001b[1;33m    return metrics\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class SteamRetrievalModel(tf.keras.Model):\n",
    "    def __init__(self, user_model, game_model, training_metrics=True):\n",
    "        super().__init__()\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.game_model: tf.keras.Model = game_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    # features / datasets should be of form {str: tensor}\n",
    "    def train_step(self, features):\n",
    "\n",
    "        # Record gradients\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Loss computation\n",
    "            user_embeddings = self.user_model(features[\"user_id\"])\n",
    "            positive_game_embeddings = self.game_model(features[\"game_id\"])\n",
    "            loss = self.task(user_embeddings, positive_game_embeddings)\n",
    "\n",
    "            # Regularization losses prevent overfitting by encouraging learning smaller weights\n",
    "            # Penalties added back into the final loss \n",
    "            regularization_loss = sum(self.losses)\n",
    "\n",
    "            total_loss = loss + regularization_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "    #if training_metrics:\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        metrics[\"loss\"] = loss\n",
    "        metrics[\"regularization_loss\"] = regularization_loss\n",
    "        metrics[\"total_loss\"] = total_loss\n",
    "    \n",
    "        return metrics\n",
    "\n",
    "    # features / datasets should be of form {str: tensor}\n",
    "    def test_step(self, features) -> tf.Tensor:\n",
    "\n",
    "        # Loss computation\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        positive_game_embeddings = self.game_model(features[\"game_id\"])\n",
    "        loss = self.task(user_embeddings, positive_game_embeddings)\n",
    "\n",
    "        regularization_loss = sum(self.losses)\n",
    "\n",
    "        total_loss = loss + regularization_loss\n",
    "\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        metrics[\"loss\"] = loss\n",
    "        metrics[\"regularization_loss\"] = regularization_loss\n",
    "        metrics[\"total_loss\"] = total_loss\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d9e9d3-bee7-49a9-843e-e34fd5cd6dec",
   "metadata": {},
   "source": [
    "### Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "02765ebc-f099-419e-bc96-b554b713993b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1478502560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[74], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    def SteamRetrievalModelSimple(tfrs.Model):\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def SteamRetrievalModelSimple(tfrs.Model):\n",
    "    \n",
    "    def __init__(self, usermodel, movie_model):\n",
    "        super().__init__()\n",
    "        self.game_model: tf.keras.Model = game_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def compute_loss(self, features):\n",
    "        user_embed = self.user_model(features[\"user_id\"])\n",
    "        positive_game_embed = self.game_model(features[\"game_id\"])\n",
    "        return self.task(user_embed, positive_game_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1c73b-b02f-4a83-b74c-da5aeccdbcb6",
   "metadata": {},
   "source": [
    "# Keras fitting and evaluation\n",
    "### Train in three epochs using gradient model AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce10983c-655a-49c5-b749-c6e370e49b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SteamRetrievalModel(user_model, game_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b59c4-9517-4428-9ae5-df0117266d25",
   "metadata": {},
   "source": [
    "### Shuffle, batch, and cache training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "58a90fd7-cd40-46e4-9012-99b8afd1dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1008c9-4f71-4185-9e9c-e233c749d301",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "af37d5b7-732a-4e7a-801f-c08f5c45602e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Bluecat\\miniconda3\\envs\\tf_conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Bluecat\\miniconda3\\envs\\tf_conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Bluecat\\miniconda3\\envs\\tf_conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Bluecat\\AppData\\Local\\Temp\\ipykernel_29056\\3440614214.py\", line 27, in train_step\n        if training_metrics:\n\n    NameError: name 'training_metrics' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcached_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf_conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileqqkutak0.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[77], line 27\u001b[0m, in \u001b[0;36mSteamRetrievalModel.train_step\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     24\u001b[0m gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(total_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(gradients, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_variables))\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtraining_metrics\u001b[49m:\n\u001b[0;32m     28\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {metric\u001b[38;5;241m.\u001b[39mname: metric\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics}\n\u001b[0;32m     29\u001b[0m     metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m loss\n",
      "\u001b[1;31mNameError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Bluecat\\miniconda3\\envs\\tf_conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Bluecat\\miniconda3\\envs\\tf_conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Bluecat\\miniconda3\\envs\\tf_conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Bluecat\\AppData\\Local\\Temp\\ipykernel_29056\\3440614214.py\", line 27, in train_step\n        if training_metrics:\n\n    NameError: name 'training_metrics' is not defined\n"
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fea622-3fbb-4a7f-9e02-90215ad31a69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
